{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"NLP_3_DNN_POS.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"view-in-github","colab_type":"text"},"source":["<a href=\"https://colab.research.google.com/github/eyalbd2/097215_Natural-Language-Processing_Workshop-Notebooks/blob/master/NLP_3_DNN_POS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"]},{"cell_type":"markdown","metadata":{"id":"8mMT5nM3hsIz","colab_type":"text"},"source":["# <img src=\"https://img.icons8.com/dusk/64/000000/mind-map.png\" style=\"height:50px;display:inline\"> IE 097215 - Technion - Natural Language Processing\n","\n","## Pytorch - Implementing a POS tagger\n","In the first assignment in the course you have implemented a POS-MEMM tagger. We have used manually handcrafted features to represent input text. In this workshop we will use a Deep Neural Network (DNN) to represent input text. This notebook includes specific modules which you can be use in the second assignment of the course."]},{"cell_type":"markdown","metadata":{"id":"GT3ffBzqkktp","colab_type":"text"},"source":["\n","\n","####**Importing all necessery packages.** "]},{"cell_type":"code","metadata":{"id":"yRhnp0-hUm4P","colab_type":"code","outputId":"0ad007e5-d7a8-4e4f-f615-19f420c09d94","executionInfo":{"status":"ok","timestamp":1589709952369,"user_tz":-180,"elapsed":32104,"user":{"displayName":"Eyal Ben David","photoUrl":"","userId":"13627541310241359464"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')\n","\n","data_dir = \"/content/gdrive/My Drive/Colab Notebooks/data/POS/\""],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3-04mAVfhkme","colab_type":"code","colab":{}},"source":["import pandas as pd\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import random\n","from torch.utils.data.dataloader import DataLoader"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SyH3INpirWv_","colab_type":"text"},"source":["####**Create Vocabulary**\n","We will first implement a util function and then we will extract vocabulary out of our data."]},{"cell_type":"code","metadata":{"id":"MGxz4MgYvfwp","colab_type":"code","colab":{}},"source":["def split(string, delimiters):\n","    \"\"\"\n","        Split strings according to delimiters\n","        :param string: full sentence\n","        :param delimiters string: characters for spliting\n","            function splits sentence to words\n","    \"\"\"\n","    delimiters = tuple(delimiters)\n","    stack = [string, ]\n","\n","    for delimiter in delimiters:\n","        for i, substring in enumerate(stack):\n","            substack = substring.split(delimiter)\n","            stack.pop(i)\n","            for j, _substring in enumerate(substack):\n","                stack.insert(i + j, _substring)\n","\n","    return stack"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zv1Mq-h1rb8T","colab_type":"code","colab":{}},"source":["def get_vocabs(list_of_paths):\n","    \"\"\"\n","        Extract vocabs from given datasets. Return a word2ids and tag2idx.\n","        :param file_paths: a list with a full path for all corpuses\n","            Return:\n","              - word2idx\n","              - tag2idx\n","    \"\"\"\n","    word_dict = defaultdict(int)\n","    pos_dict = defaultdict(int)\n","    for file_path in list_of_paths:\n","        with open(file_path) as f:\n","            for line in f:\n","                splited_words = split(line, (' ', '\\n'))\n","                del splited_words[-1]\n","                for word_and_tag in splited_words:\n","                    word, pos_tag = split(word_and_tag, '_')\n","                    word_dict[word] += 1\n","                    pos_dict[pos_tag] += 1\n","\n","    return word_dict, pos_dict\n","# ******************* USAGE EXAMPLE (this is good practice) *******************\n","# path_train = \"data/train.wtag\"\n","# path_test = \"data/test.wtag\"\n","# paths_list = [path_train, path_test]\n","# word_dict, pos_dict = get_vocabs(paths_list)\n","# *****************************************************************************"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"l1cfc2xkAiEf","colab_type":"text"},"source":["####**Data Reader**"]},{"cell_type":"code","metadata":{"id":"LN389bwRAn1E","colab_type":"code","colab":{}},"source":["from collections import defaultdict\n","\n","class PosDataReader:\n","    def __init__(self, file, word_dict, pos_dict):\n","        self.file = file\n","        self.word_dict = word_dict\n","        self.pos_dict = pos_dict\n","        self.sentences = []\n","        self.__readData__()\n","    \n","    def __readData__(self):\n","        \"\"\"main reader function which also populates the class data structures\"\"\"\n","        with open(self.file, 'r') as f:\n","          for line in f:\n","              cur_sentence = []\n","              splited_words = split(line, (' ', '\\n'))\n","              del splited_words[-1]\n","              for word_and_tag in splited_words:\n","                  cur_word, cur_tag = split(word_and_tag, '_')\n","                  cur_sentence.append((cur_word, cur_tag))\n","              self.sentences.append(cur_sentence)\n","\n","    def get_num_sentences(self):\n","        \"\"\"returns num of sentences in data\"\"\"\n","        return len(self.sentences)\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"h2oa34ha7zr4","colab_type":"text"},"source":["####**Dataset**"]},{"cell_type":"code","metadata":{"id":"vtmygai-77n7","colab_type":"code","colab":{}},"source":["from torchtext.vocab import Vocab\n","from torch.utils.data.dataset import Dataset, TensorDataset\n","from pathlib import Path\n","from collections import Counter\n","\n","# These are not relevant for our POS tagger but might be usefull for HW2\n","UNKNOWN_TOKEN = \"<unk>\"\n","PAD_TOKEN = \"<pad>\" # Optional: this is used to pad a batch of sentences in different lengths.\n","# ROOT_TOKEN = PAD_TOKEN # this can be used if you are not padding your batches\n","# ROOT_TOKEN = \"<root>\" # use this if you are padding your batches and want a special token for ROOT\n","SPECIAL_TOKENS = [PAD_TOKEN, UNKNOWN_TOKEN]\n","\n","\n","class PosDataset(Dataset):\n","    def __init__(self, word_dict, pos_dict, dir_path: str, subset: str, \n","                 padding=False, word_embeddings=None):\n","        super().__init__()\n","        self.subset = subset # One of the following: [train, test]\n","        self.file = dir_path + subset + \".wtag\"\n","        self.datareader = PosDataReader(self.file, word_dict, pos_dict)\n","        self.vocab_size = len(self.datareader.word_dict)\n","        if word_embeddings:\n","            self.word_idx_mappings, self.idx_word_mappings, self.word_vectors = word_embeddings\n","        else:\n","            self.word_idx_mappings, self.idx_word_mappings, self.word_vectors = self.init_word_embeddings(self.datareader.word_dict)\n","        self.pos_idx_mappings, self.idx_pos_mappings = self.init_pos_vocab(self.datareader.pos_dict)\n","        \n","        self.pad_idx = self.word_idx_mappings.get(PAD_TOKEN)\n","        self.unknown_idx = self.word_idx_mappings.get(UNKNOWN_TOKEN)\n","        self.word_vector_dim = self.word_vectors.size(-1)\n","        self.sentence_lens = [len(sentence) for sentence in self.datareader.sentences]\n","        self.max_seq_len = max(self.sentence_lens)\n","        self.sentences_dataset = self.convert_sentences_to_dataset(padding)\n","\n","    def __len__(self):\n","        return len(self.sentences_dataset)\n","\n","    def __getitem__(self, index):\n","        word_embed_idx, pos_embed_idx, sentence_len = self.sentences_dataset[index]\n","        return word_embed_idx, pos_embed_idx, sentence_len\n","\n","    @staticmethod\n","    def init_word_embeddings(word_dict):\n","        glove = Vocab(Counter(word_dict), vectors=\"glove.6B.300d\", specials=SPECIAL_TOKENS)\n","        return glove.stoi, glove.itos, glove.vectors\n","\n","    def get_word_embeddings(self):\n","        return self.word_idx_mappings, self.idx_word_mappings, self.word_vectors\n","\n","    def init_pos_vocab(self, pos_dict):\n","        idx_pos_mappings = sorted([self.word_idx_mappings.get(token) for token in SPECIAL_TOKENS])\n","        pos_idx_mappings = {self.idx_word_mappings[idx]: idx for idx in idx_pos_mappings}\n","        \n","        for i, pos in enumerate(sorted(pos_dict.keys())):\n","            # pos_idx_mappings[str(pos)] = int(i)\n","            pos_idx_mappings[str(pos)] = int(i+len(SPECIAL_TOKENS))\n","            idx_pos_mappings.append(str(pos))\n","        print(\"idx_pos_mappings -\", idx_pos_mappings)\n","        print(\"pos_idx_mappings -\", pos_idx_mappings)\n","        return pos_idx_mappings, idx_pos_mappings\n","        \n","    def get_pos_vocab(self):\n","        return self.pos_idx_mappings, self.idx_pos_mappings\n","\n","    def convert_sentences_to_dataset(self, padding):\n","        sentence_word_idx_list = list()\n","        sentence_pos_idx_list = list()\n","        sentence_len_list = list()\n","        for sentence_idx, sentence in enumerate(self.datareader.sentences):\n","            words_idx_list = []\n","            pos_idx_list = []\n","            for word, pos in sentence:\n","                words_idx_list.append(self.word_idx_mappings.get(word))\n","                pos_idx_list.append(self.pos_idx_mappings.get(pos))\n","            sentence_len = len(words_idx_list)\n","            # if padding:\n","            #     while len(words_idx_list) < self.max_seq_len:\n","            #         words_idx_list.append(self.word_idx_mappings.get(PAD_TOKEN))\n","            #         pos_idx_list.append(self.pos_idx_mappings.get(PAD_TOKEN))\n","            sentence_word_idx_list.append(torch.tensor(words_idx_list, dtype=torch.long, requires_grad=False))\n","            sentence_pos_idx_list.append(torch.tensor(pos_idx_list, dtype=torch.long, requires_grad=False))\n","            sentence_len_list.append(sentence_len)\n","        \n","        # if padding:\n","        #     all_sentence_word_idx = torch.tensor(sentence_word_idx_list, dtype=torch.long)\n","        #     all_sentence_pos_idx = torch.tensor(sentence_pos_idx_list, dtype=torch.long)\n","        #     all_sentence_len = torch.tensor(sentence_len_list, dtype=torch.long, requires_grad=False)\n","        #     return TensorDataset(all_sentence_word_idx, all_sentence_pos_idx, all_sentence_len)\n","            \n","        return {i: sample_tuple for i, sample_tuple in enumerate(zip(sentence_word_idx_list,\n","                                                                     sentence_pos_idx_list,\n","                                                                     sentence_len_list))}"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"38ZjxNKovpLi","colab_type":"code","outputId":"b4e502fa-7f9c-4074-848b-810a00539c07","executionInfo":{"status":"ok","timestamp":1589710420334,"user_tz":-180,"elapsed":499872,"user":{"displayName":"Eyal Ben David","photoUrl":"","userId":"13627541310241359464"}},"colab":{"base_uri":"https://localhost:8080/","height":156}},"source":["path_train = data_dir + \"train.wtag\"\n","print(\"path_train -\", path_train)\n","path_test = data_dir + \"test.wtag\"\n","print(\"path_test -\", path_test)\n","\n","paths_list = [path_train, path_test]\n","word_dict, pos_dict = get_vocabs(paths_list)\n","train = PosDataset(word_dict, pos_dict, data_dir, 'train', padding=False)\n","train_dataloader = DataLoader(train, shuffle=True)\n","test = PosDataset(word_dict, pos_dict, data_dir, 'test', padding=False)\n","test_dataloader = DataLoader(test, shuffle=False)\n","\n","\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["path_train - /content/gdrive/My Drive/Colab Notebooks/data/POS/train.wtag\n","path_test - /content/gdrive/My Drive/Colab Notebooks/data/POS/test.wtag\n"],"name":"stdout"},{"output_type":"stream","text":[".vector_cache/glove.6B.zip: 862MB [06:30, 2.21MB/s]                           \n","100%|█████████▉| 398971/400000 [00:37<00:00, 10812.02it/s]"],"name":"stderr"},{"output_type":"stream","text":["idx_pos_mappings - [0, 1, '#', '$', \"''\", ',', '-LRB-', '-RRB-', '.', ':', 'CC', 'CD', 'DT', 'EX', 'FW', 'IN', 'JJ', 'JJR', 'JJS', 'MD', 'NN', 'NNP', 'NNPS', 'NNS', 'PDT', 'POS', 'PRP', 'PRP$', 'RB', 'RBR', 'RBS', 'RP', 'SYM', 'TO', 'UH', 'VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ', 'WDT', 'WP', 'WP$', 'WRB', '``']\n","pos_idx_mappings - {'<pad>': 0, '<unk>': 1, '#': 2, '$': 3, \"''\": 4, ',': 5, '-LRB-': 6, '-RRB-': 7, '.': 8, ':': 9, 'CC': 10, 'CD': 11, 'DT': 12, 'EX': 13, 'FW': 14, 'IN': 15, 'JJ': 16, 'JJR': 17, 'JJS': 18, 'MD': 19, 'NN': 20, 'NNP': 21, 'NNPS': 22, 'NNS': 23, 'PDT': 24, 'POS': 25, 'PRP': 26, 'PRP$': 27, 'RB': 28, 'RBR': 29, 'RBS': 30, 'RP': 31, 'SYM': 32, 'TO': 33, 'UH': 34, 'VB': 35, 'VBD': 36, 'VBG': 37, 'VBN': 38, 'VBP': 39, 'VBZ': 40, 'WDT': 41, 'WP': 42, 'WP$': 43, 'WRB': 44, '``': 45}\n","idx_pos_mappings - [0, 1, '#', '$', \"''\", ',', '-LRB-', '-RRB-', '.', ':', 'CC', 'CD', 'DT', 'EX', 'FW', 'IN', 'JJ', 'JJR', 'JJS', 'MD', 'NN', 'NNP', 'NNPS', 'NNS', 'PDT', 'POS', 'PRP', 'PRP$', 'RB', 'RBR', 'RBS', 'RP', 'SYM', 'TO', 'UH', 'VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ', 'WDT', 'WP', 'WP$', 'WRB', '``']\n","pos_idx_mappings - {'<pad>': 0, '<unk>': 1, '#': 2, '$': 3, \"''\": 4, ',': 5, '-LRB-': 6, '-RRB-': 7, '.': 8, ':': 9, 'CC': 10, 'CD': 11, 'DT': 12, 'EX': 13, 'FW': 14, 'IN': 15, 'JJ': 16, 'JJR': 17, 'JJS': 18, 'MD': 19, 'NN': 20, 'NNP': 21, 'NNPS': 22, 'NNS': 23, 'PDT': 24, 'POS': 25, 'PRP': 26, 'PRP$': 27, 'RB': 28, 'RBR': 29, 'RBS': 30, 'RP': 31, 'SYM': 32, 'TO': 33, 'UH': 34, 'VB': 35, 'VBD': 36, 'VBG': 37, 'VBN': 38, 'VBP': 39, 'VBZ': 40, 'WDT': 41, 'WP': 42, 'WP$': 43, 'WRB': 44, '``': 45}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jYwuXpdhzZ_T","colab_type":"code","outputId":"ef40b832-6569-4b5e-e339-9aa0ece3b2a8","executionInfo":{"status":"ok","timestamp":1589710420337,"user_tz":-180,"elapsed":499856,"user":{"displayName":"Eyal Ben David","photoUrl":"","userId":"13627541310241359464"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["print(\"Number of Train Tagged Sentences \", len(train))\n","print(\"Number of Test Tagged Sentences \",len(test))\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Number of Train Tagged Sentences  5000\n","Number of Test Tagged Sentences  1000\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"o1eWUr9loluL","colab_type":"text"},"source":["####**Create a model**\n","\n","We will implement an LSTM model and a Viterbi based LSTM model."]},{"cell_type":"code","metadata":{"id":"G_yXx9SVMSkK","colab_type":"code","colab":{}},"source":["class DnnPosTagger(nn.Module):\n","    def __init__(self, word_embeddings, hidden_dim, word_vocab_size, tag_vocab_size):\n","        super(DnnPosTagger, self).__init__()\n","        emb_dim = word_embeddings.shape[1]\n","        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","        #self.word_embedding = nn.Embedding(word_vocab_size, word_embedding_dim)\n","        self.word_embedding = nn.Embedding.from_pretrained(word_embeddings, freeze=False)\n","        self.lstm = nn.LSTM(input_size=emb_dim, hidden_size=hidden_dim, num_layers=2, bidirectional=True, batch_first=False)\n","        self.hidden2tag = nn.Linear(hidden_dim*2, tag_vocab_size)\n","\n","        \n","    def forward(self, word_idx_tensor):\n","        embeds = self.word_embedding(word_idx_tensor.to(self.device))   # [batch_size, seq_length, emb_dim]      \n","        lstm_out, _ = self.lstm(embeds.view(embeds.shape[1], 1, -1))    # [seq_length, batch_size, 2*hidden_dim]\n","        tag_space = self.hidden2tag(lstm_out.view(embeds.shape[1], -1)) # [seq_length, tag_dim]\n","        tag_scores = F.log_softmax(tag_space, dim=1)                    # [seq_length, tag_dim]\n","        return tag_scores"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mtRA1lM3o3lT","colab_type":"text"},"source":["####**Evaluation Method**"]},{"cell_type":"code","metadata":{"id":"vpjCZB6jo755","colab_type":"code","colab":{}},"source":["def evaluate():\n","    acc = 0\n","    with torch.no_grad():\n","        for batch_idx, input_data in enumerate(test_dataloader):\n","            \n","            words_idx_tensor, pos_idx_tensor, sentence_length = input_data  \n","            tag_scores = model(words_idx_tensor)\n","            tag_scores = tag_scores.unsqueeze(0).permute(0,2,1)\n","            \n","            _, indices = torch.max(tag_scores, 1)\n","            acc += torch.mean(torch.tensor(pos_idx_tensor.to(\"cpu\") == indices.to(\"cpu\"), dtype=torch.float))\n","        acc = acc / len(test)\n","    return acc"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_pTF2lREpBFO","colab_type":"text"},"source":["####**Training The LSTM Model**"]},{"cell_type":"code","metadata":{"id":"iMTpPt6NMmGU","colab_type":"code","outputId":"93fee813-8329-416f-e19d-8a596e1db7a5","executionInfo":{"status":"ok","timestamp":1589711499742,"user_tz":-180,"elapsed":1579184,"user":{"displayName":"Eyal Ben David","photoUrl":"","userId":"13627541310241359464"}},"colab":{"base_uri":"https://localhost:8080/","height":360}},"source":["#CUDA_LAUNCH_BLOCKING=1  \n","\n","EPOCHS = 15\n","WORD_EMBEDDING_DIM = 100\n","HIDDEN_DIM = 1000\n","word_vocab_size = len(train.word_idx_mappings)\n","tag_vocab_size = len(train.pos_idx_mappings)\n","\n","model = DnnPosTagger(train_dataloader.dataset.word_vectors, HIDDEN_DIM, word_vocab_size, tag_vocab_size)\n","\n","use_cuda = torch.cuda.is_available()\n","device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n","\n","if use_cuda:\n","    model.cuda()\n","\n","# Define the loss function as the Negative Log Likelihood loss (NLLLoss)\n","loss_function = nn.NLLLoss()\n","\n","# We will be using a simple SGD optimizer to minimize the loss function\n","optimizer = optim.Adam(model.parameters(), lr=0.01)\n","acumulate_grad_steps = 50 # This is the actual batch_size, while we officially use batch_size=1\n","\n","# Training start\n","print(\"Training Started\")\n","accuracy_list = []\n","loss_list = []\n","epochs = EPOCHS\n","for epoch in range(epochs):\n","    acc = 0 # to keep track of accuracy\n","    printable_loss = 0 # To keep track of the loss value\n","    i = 0\n","    for batch_idx, input_data in enumerate(train_dataloader):\n","        i += 1\n","        words_idx_tensor, pos_idx_tensor, sentence_length = input_data\n","        \n","        tag_scores = model(words_idx_tensor)\n","        tag_scores = tag_scores.unsqueeze(0).permute(0,2,1)\n","        #print(\"tag_scores shape -\", tag_scores.shape)\n","        #print(\"pos_idx_tensor shape -\", pos_idx_tensor.shape)\n","        loss = loss_function(tag_scores, pos_idx_tensor.to(device))\n","        loss = loss / acumulate_grad_steps\n","        loss.backward()\n","\n","        if i % acumulate_grad_steps == 0:\n","            optimizer.step()\n","            model.zero_grad()\n","        printable_loss += loss.item()\n","        _, indices = torch.max(tag_scores, 1)\n","        # print(\"tag_scores shape-\", tag_scores.shape)\n","        # print(\"indices shape-\", indices.shape)\n","        # acc += indices.eq(pos_idx_tensor.view_as(indices)).mean().item()\n","        acc += torch.mean(torch.tensor(pos_idx_tensor.to(\"cpu\") == indices.to(\"cpu\"), dtype=torch.float))\n","    printable_loss = printable_loss / len(train)\n","    acc = acc / len(train)\n","    loss_list.append(float(printable_loss))\n","    accuracy_list.append(float(acc))\n","    test_acc = evaluate()\n","    e_interval = i\n","    print(\"Epoch {} Completed,\\tLoss {}\\tAccuracy: {}\\t Test Accuracy: {}\".format(epoch + 1, np.mean(loss_list[-e_interval:]), np.mean(accuracy_list[-e_interval:]), test_acc))\n","        "],"execution_count":0,"outputs":[{"output_type":"stream","text":["\r100%|█████████▉| 398971/400000 [00:50<00:00, 10812.02it/s]"],"name":"stderr"},{"output_type":"stream","text":["Training Started\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  # This is added back by InteractiveShellApp.init_path()\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1 Completed,\tLoss 0.05435596079258248\tAccuracy: 0.2656257152557373\t Test Accuracy: 0.47855710983276367\n","Epoch 2 Completed,\tLoss 0.03576184127254528\tAccuracy: 0.5208622813224792\t Test Accuracy: 0.8844269514083862\n","Epoch 3 Completed,\tLoss 0.02586716541693507\tAccuracy: 0.6554659008979797\t Test Accuracy: 0.9045175313949585\n","Epoch 4 Completed,\tLoss 0.020271231177345545\tAccuracy: 0.7303514033555984\t Test Accuracy: 0.9106523990631104\n","Epoch 5 Completed,\tLoss 0.016707569406348776\tAccuracy: 0.7776372790336609\t Test Accuracy: 0.9197829961776733\n","Epoch 6 Completed,\tLoss 0.014239116449190079\tAccuracy: 0.8102470139662424\t Test Accuracy: 0.9223999381065369\n","Epoch 7 Completed,\tLoss 0.012422604812690198\tAccuracy: 0.8341747266905648\t Test Accuracy: 0.9255969524383545\n","Epoch 8 Completed,\tLoss 0.011037156624331464\tAccuracy: 0.8523860424757004\t Test Accuracy: 0.9201141595840454\n","Epoch 9 Completed,\tLoss 0.00994286882162011\tAccuracy: 0.8667581743664212\t Test Accuracy: 0.9254709482192993\n","Epoch 10 Completed,\tLoss 0.009053708024420147\tAccuracy: 0.8784776985645294\t Test Accuracy: 0.9225422143936157\n","Epoch 11 Completed,\tLoss 0.008320249209040391\tAccuracy: 0.8881727023558184\t Test Accuracy: 0.9212234616279602\n","Epoch 12 Completed,\tLoss 0.007694431935358636\tAccuracy: 0.8964736411968867\t Test Accuracy: 0.927778422832489\n","Epoch 13 Completed,\tLoss 0.007155671115174431\tAccuracy: 0.9036379823317895\t Test Accuracy: 0.923854649066925\n","Epoch 14 Completed,\tLoss 0.006689078071447389\tAccuracy: 0.9098471828869411\t Test Accuracy: 0.9197566509246826\n","Epoch 15 Completed,\tLoss 0.006282186654693306\tAccuracy: 0.9152658025423686\t Test Accuracy: 0.9220077991485596\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"rFyD2IjBpWij","colab_type":"text"},"source":["####**Plot Training Results**"]},{"cell_type":"code","metadata":{"id":"5i5mwQ4PpcXx","colab_type":"code","outputId":"f0c287c9-b203-403c-9efa-7d17cc34c44d","executionInfo":{"status":"ok","timestamp":1589711500264,"user_tz":-180,"elapsed":1579690,"user":{"displayName":"Eyal Ben David","photoUrl":"","userId":"13627541310241359464"}},"colab":{"base_uri":"https://localhost:8080/","height":541}},"source":["import matplotlib.pyplot as plt\n","\n","plt.plot(accuracy_list, c=\"red\", label =\"Accuracy\")\n","plt.xlabel(\"Epochs\")\n","plt.ylabel(\"Value\")\n","plt.legend()\n","plt.show()\n","\n","plt.plot(loss_list, c=\"blue\", label =\"Loss\")\n","plt.xlabel(\"Epochs\")\n","plt.ylabel(\"Value\")\n","plt.legend()\n","plt.show()"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3df5wV9X3v8deb3UUgChogSlh0SUACMWLMqq3mUblRGrRRNNwarDVqvBqbgDaNuWKbGmPaNL813nCT0NRfiYIWU0MsV2PU/siNqaxKtMpB9gKGJXhZlYAKKyz76R9zjhyX/c3Oztmd9/PxmMc58z2zZz5nH7vf95mZ78woIjAzs/walnUBZmaWLQeBmVnOOQjMzHLOQWBmlnMOAjOznKvOuoDeGjduXNTV1WVdhpnZoPLEE0+8FBHjO3pt0AVBXV0dDQ0NWZdhZjaoSHqhs9e8a8jMLOccBGZmOecgMDPLudSCQNItkrZK+s9OXpekmyU1Snpa0vFp1WJmZp1Lc4vgNmBOF6+fAUwtTpcD302xFjMz60RqQRAR/wa80sUic4E7IvEr4FBJE9Kqx8zMOpblMYKJwKay+aZi234kXS6pQVJDc3PzgBRnZpYXg+I8gohYAiwBqK+v93Wzzaxv9u6F3bv3TXv2JG0dTa2tnb/W3fJtbRCRPJZP7dt6u8xZZ8EJJ/T7ryXLINgMTCqbry22mdlQEQEtLcm0a9eBPZZ34KVOvH1bd8u0tWX9G+k7CSZOHHJBsAJYIGkZcBKwPSK2ZFiPWWVrbYU33kimlpZ9z3sydbR86dtwa+tbp/ZtvV2mvON/440D+8wjRuybDjoIampg+PD9p1GjOm7vbPnSazU1UFW1/1Rd3XF7V1P5zwwbtv8kdT3f1TJSMqUktSCQtBSYBYyT1AR8AagBiIjvASuBM4FGYCdwSVq1mHUrIunM2neWu3f3rq27b6h9mUrr6K9vs8OG7etUq6v3TaXOrKu2qioYObLr10sd98iRyVR63v6xq9dKHf8wn+o0EFILgog4v5vXA/h0Wuu3Ia61FXbs2Ddt3975fPvXduzY9221fOrP27ZKSUfW2bfR9t9mDz2062UOOqjjqdRh9nQaMSLpsM3K+C/CsrVzJzQ3dz5t29Zxh75zZ/fvPWwYjB4NY8Ykj6NHw/jx8O53J986yzvIjjrbnra1bx8+PPlmbDZIOAis/0QknXWpE3/ppa47+ebm5Jt5R2pqkk77sMOSjnzsWHjXu/Z16O07+PLnpflRo1Ldr2o2VDgIrHd27oTGRnj++X3TunWwcWPSse/Z0/HPjRqVdOzjx8M73gHvfe+++XHj9j0vTaNHuxM3GyAOAtvfnj2wYcO+Tr68029qeuuyEyfC0UfDnDlJB9++Qy919KNGZfNZzKxbDoK8amtLOvX2Hf26dbB+fTKCpuTtb086+w99KHmcOjV5nDIFDj44u89gZv3CQZAXLS2wYgXcey+sWZN0+C0t+14fNSrp4I87Ds47L+noS53+2LHZ1W1mqXMQDGUR8NRTcMstcNddyQicd74TPvABmD17X2d/9NFJu/fJm+WSg2Aoam6GO++EW2+Fp59OhjSeey5ccgmcdpqHNprZWzgIhorWVnjggaTz/+lPkwO+9fWweDGcf34yDNPMrAMOgsGuUEg6/zvugBdfTEbpLFiQfPt/3/uyrs7MBgEHwWC0YwfcfXcSAI89luzqOfNM+MQnksfhw7Ou0MwGEQfBYNHWBv/6r0nnv3x5ckbu9Onw9a/Dn/4pHHFE1hWa2SDlIKh0L7wAt98Ot92WnOQ1ejR8/OPJrp8TT/RIHzM7YA6CSvXP/ww33QQPP5wMAz3tNPjSl5LRPz5L18z6kYOgEj3zTHJLuiOPhC98AS66COrqsq7KzIYoB0El+su/THYBPflkcnkHM7MU+fY/lebf/x3uvx8WLXIImNmAcBBUkgi45prkcg9XXpl1NWaWE6kGgaQ5ktZKapS0qIPXj5L0sKSnJf2LpNo066l4K1Yk5wVcf70PCJvZgEktCCRVAYuBM4AZwPmSZrRb7BvAHRFxLHAD8Hdp1VPxWlvh2mth2rRkaKiZ2QBJc4vgRKAxItZHxG5gGTC33TIzgEeKzx/t4PX8uOOO5PLQX/6yby5uZgMqzSCYCGwqm28qtpX7NfDR4vNzgUMk7Xfxe0mXS2qQ1NDc3JxKsZnatQuuuw5OOik5T8DMbABlfbD4auBUSU8BpwKbgb3tF4qIJRFRHxH148ePH+ga0/ed78DmzfDVr/pMYTMbcGnug9gMTCqbry22vSkifktxi0DSwcC8iPhdijVVnm3bkt1BZ5wBp56adTVmlkNpbhGsAqZKmixpODAfWFG+gKRxkko1XAvckmI9lemrX4Xt2+Hv8nuc3MyylVoQREQrsAB4EFgD3BMRz0q6QdLZxcVmAWslPQ8cDvxtWvVUpKYm+Pa34YILYObMrKsxs5xSRGRdQ6/U19dHQ0ND1mX0j8suS0YLrV3rawmZWaokPRER9R29lvXB4vxasya5qfyf/ZlDwMwy5SDIyl/9FbztbcmjmVmGHARZeOwx+Kd/gs99LrnHsJlZhhwEA610YbnDD4fPfCbraszMfD+CAbdyZXKp6cWL4eCDs67GzMxbBANq797kwnJTpiQjhszMKoC3CAbSnXcmt6FctgxqarKuxswM8BbBwGlpgb/+a/jAB+CP/zjraszM3uQtgoHy3e/Cb34D//APMMz5a2aVwz3SQNi+Hf72b2H2bDj99KyrMTN7CwfBQPj61+Hll+ErX8m6EjOz/TgI0rZlC9x4I8yfD8cfn3U1Zmb7cRCk7Utfgt27k0czswrkIEjTunWwZAl88pPJuQNmZhXIQZCmz38eRoxIho2amVUoB0FaGhrgnnvgL/4iua6QmVmFchCkoXRhuXHj4Oqrs67GzKxLPqEsDQ89BI88AjfdBKNHZ12NmVmXUt0ikDRH0lpJjZIWdfD6kZIelfSUpKclnZlmPQOirQ0WLUruOnbFFVlXY2bWrdS2CCRVAYuB2UATsErSioh4rmyxz5Pc1P67kmYAK4G6tGoaEHffDU89BT/8IRx0UNbVmJl1K80tghOBxohYHxG7gWXA3HbLBFDadzIG+G2K9aRv9+5kpNDMmfAnf5J1NWZmPZLmMYKJwKay+SbgpHbLXA/8TNJC4G1AhxfikXQ5cDnAkUce2e+F9pslS2D9+uTmM76wnJkNEln3VucDt0VELXAm8ENJ+9UUEUsioj4i6sdX6j1+X301OXt41iyYMyfraszMeizNLYLNwKSy+dpiW7lLgTkAEfGYpBHAOGBrinWl41vfgq1bYcUKkLKuxsysx9LcIlgFTJU0WdJwYD6wot0yvwFOA5A0HRgBNKdYUzq2boVvfAPmzYOT2u/9MjOrbKkFQUS0AguAB4E1JKODnpV0g6Szi4t9FrhM0q+BpcDFERFp1ZSav/kb2LUrueeAmdkgk+oJZRGxkmRIaHnbdWXPnwNOSbOG1K1fD9/7Hlx6KUyblnU1Zma9lvXB4sHvy1+G6mr4wheyrsTMrE8cBAfqscfgD/8Q3vnOrCsxM+sTB8GBaG1N7jkwfXrWlZiZ9ZmD4EBs2AB79sB73pN1JWZmfeYgOBCFQvLoIDCzQcxBcCBKQeDRQmY2iDkIDkShAEccAYcemnUlZmZ95iA4EIWCdwuZ2aDnIOirCFizxkFgZoOeg6CvXnoJtm1zEJjZoOcg6CuPGDKzIcJB0FcOAjMbIhwEfVUowMiRMGlS98uamVUwB0FfFQrJ+QO+JaWZDXLuxfrKQ0fNbIhwEPRFS0tynSEHgZkNAQ6Cvli3LjmPwEFgZkOAg6AvPGLIzIaQVINA0hxJayU1SlrUwes3SlpdnJ6X9Ls06+k3hQJIMHVq1pWYmR2w1O5ZLKkKWAzMBpqAVZJWFO9TDEBEfKZs+YXA+9Oqp18VCnDUUTBqVNaVmJkdsDS3CE4EGiNifUTsBpYBc7tY/nxgaYr19B+PGDKzISTNIJgIbCqbbyq27UfSUcBk4JEU6+kfbW0OAjMbUirlYPF8YHlE7O3oRUmXS2qQ1NDc3DzApbWzeTPs3OkgMLMhI80g2AyUX3+httjWkfl0sVsoIpZERH1E1I8fP74fS+wDjxgysyEmzSBYBUyVNFnScJLOfkX7hSS9BzgMeCzFWvqPg8DMhpjUgiAiWoEFwIPAGuCeiHhW0g2Szi5bdD6wLCIirVr6VaGQ3JryHe/IuhIzs36R2vBRgIhYCaxs13Zdu/nr06yh35UOFEtZV2Jm1i8q5WDx4OERQ2Y2xDgIemPHDvjtbx0EZjakOAh6Y+3a5NFBYGZDSI+DQJKvp+ARQ2Y2BHUbBJJOlvQcUCjOz5T0v1OvrBIVClBdDe96V9aVmJn1m55sEdwIfBh4GSAifg38QZpFVaxCAaZMgZqarCsxM+s3Pdo1FBGb2jV1eCmIIc8jhsxsCOpJEGySdDIQkmokXU1ygli+tLYmdyZzEJjZENOTILgC+DTJlUM3A8cV5/NlwwbYs8dBYGZDTrdnFkfES8AFA1BLZfOIITMboroNAkm3AvtdBygiPpFKRZWqFATTpmVbh5lZP+vJtYbuL3s+AjgX+G065VSwQgGOOCK54JyZ2RDSk11D95bPS1oK/CK1iiqVRwyZ2RDVl0tMTAXydQ3mCFizxkFgZkNST44RvEpyjEDFxxeBa1Kuq7K89BJs2+YgMLMhqSe7hg4ZiEIqmkcMmdkQ1mkQSDq+qx+MiCf7v5wK5SAwsyGsqy2Cb3bxWgAf6udaKteaNTByJEyalHUlZmb9rtMgiIj/NpCFVLRCITl/YJhv32BmQ0+PejZJx0g6T9LHS1MPf26OpLWSGiUt6mSZ8yQ9J+lZSXf1pvgB46GjZjaE9WTU0BeAWcAMkhvRn0FyHsEd3fxcFbAYmA00AaskrYiI58qWmQpcC5wSEdskVd6w1F27YONGuOiirCsxM0tFT7YI/jtwGvBiRFwCzATG9ODnTgQaI2J9ROwGlgFz2y1zGbA4IrYBRMTWHlc+UNatS84j8BaBmQ1RPQmClohoA1oljQa2Aj05ajoRKL+PQVOxrdzRwNGS/q+kX0ma09EbSbpcUoOkhubm5h6suh95xJCZDXGdBoGkxZI+CDwu6VDg74EngCeBx/pp/dUkZyrPAs4H/r64rreIiCURUR8R9ePHj++nVfdQoQASTJ06sOs1MxsgXR0jeB74OvBO4HVgKcn+/tER8XQP3nszb91yqC22lWsC/iMi9gAbJD1PEgyrelb+ACgU4KijYNSorCsxM0tFp1sEEfHtiPh9kvsTvwzcAjwAnFs8yNudVcBUSZMlDQfmAyvaLXMfydYAksaR7Cpa39sPkSqPGDKzIa7bYwQR8UJEfDUi3k+y++YcoNCDn2sFFgAPktza8p6IeFbSDZLOLi72IPCypOeAR4HPRcTLffws/a+tDdaudRCY2ZDWk+Gj1SRDRueTjB76F+D6nrx5RKwkGXJa3nZd2fMA/qI4VZ6mJti500FgZkNaV9camk2yBXAm8DjJ8M/LI+L1Aaotex4xZGY50NUWwbXAXcBnS+P8c8dBYGY50NW1hvJzUbnOFArJrSnfUXknPJuZ9RdfRa0rpRFDUtaVmJmlxkHQFQ8dNbMccBB0Zvt22LLFQWBmQ56DoDNr1yaPDgIzG+IcBJ3xiCEzywkHQWcKBaiuhne9K+tKzMxS5SDoTKEAU6ZATU3WlZiZpcpB0BmPGDKznHAQdGTPHmhsdBCYWS44CDqyYUMSBg4CM8sBB0FHSiOGpk/Ptg4zswHgIOhIKQimTcu2DjOzAeAg6EihABMmwJgxWVdiZpY6B0FHPGLIzHLEQdBehIPAzHIl1SCQNEfSWkmNkhZ18PrFkpolrS5O/yPNenqkuRm2bXMQmFludHvP4r6SVAUsBmYDTcAqSSsi4rl2i94dEQvSqqPXfI0hM8uZNLcITgQaI2J9ROwmuefx3BTX1z8cBGaWM2kGwURgU9l8U7GtvXmSnpa0XNKkjt5I0uWSGiQ1NDc3p1HrPoUCjBoFtbXprsfMrEJkfbD4p0BdRBwLPATc3tFCEbEkIuojon78+PHpVlQoJOcPDMv6V2NmNjDS7O02A+Xf8GuLbW+KiJcj4o3i7A+AD6RYT894xJCZ5UyaQbAKmCppsqThwHxgRfkCkiaUzZ4NrEmxnu7t2gUbNzoIzCxXUhs1FBGtkhYADwJVwC0R8aykG4CGiFgBXCnpbKAVeAW4OK16emTduuQ8AgeBmeVIakEAEBErgZXt2q4re34tcG2aNfSKRwyZWQ75iGi5QgEkmDo160rMzAaMg6BcoQB1dTByZNaVmJkNGAdBOY8YMrMcchCUtLXB2rUOAjPLHQdBSVMT7NzpIDCz3HEQlHjEkJnllIOgxEFgZjnlICgpFOCwwyDtaxmZmVUYB0FJacSQlHUlZmYDykFQ4qGjZpZTDgKA7dthyxYHgZnlkoMAkvMHwEFgZrnkIACPGDKzXHMQQBIENTUweXLWlZiZDTgHASRBMGVKEgZmZjnjIACPGDKzXHMQ7NkDjY0OAjPLLQfBhg1JGDgIzCynUg0CSXMkrZXUKGlRF8vNkxSS6tOsp0MeMWRmOZdaEEiqAhYDZwAzgPMlzehguUOAq4D/SKuWLpWCYNq0TFZvZpa1NLcITgQaI2J9ROwGlgFzO1juS8BXgZYUa+lcoQATJsCYMZms3swsa2kGwURgU9l8U7HtTZKOByZFxD939UaSLpfUIKmhubm5f6v0iCEzy7nMDhZLGgZ8C/hsd8tGxJKIqI+I+vH9eZnoCAeBmeVemkGwGZhUNl9bbCs5BDgG+BdJG4HfA1YM6AHj5mbYts1BYGa5lmYQrAKmSposaTgwH1hRejEitkfEuIioi4g64FfA2RHRkGJNb+URQ2Zm6QVBRLQCC4AHgTXAPRHxrKQbJJ2d1np7xUFgZkZ1mm8eESuBle3arutk2Vlp1tKhQgFGjYLa2gFftZlZpcj3mcWFQnL+wLB8/xrMLN/y3QN6xJCZWY6DYNcu2LjRQWBmuZffIFi3LjmPwEFgZjmX3yDwiCEzMyDvQSDB1KlZV2Jmlql8B0FdHYwcmXUlZmaZyncQeLeQmVlOg6CtDdaudRCYmZHXIGhqgp07HQRmZuQ1CNasSR4dBGZmOQ0CDx01M3tTfoPgsMOgP29yY2Y2SOU3CN7znuQ8AjOznMt3EJiZWQ6D4He/gxdfdBCYmRXlLwjWrk0eHQRmZkAeg8AjhszM3iLVW1VKmgN8G6gCfhARX2n3+hXAp4G9wGvA5RHxXJo1UShATQ1Mnpzqasys9/bs2UNTUxMtLS1ZlzJojRgxgtraWmpqanr8M6kFgaQqYDEwG2gCVkla0a6jvysivldc/mzgW8CctGoCkiCYMiUJAzOrKE1NTRxyyCHU1dUhj+rrtYjg5Zdfpqmpicm9+LKb5q6hE4HGiFgfEbuBZcDc8gUiYkfZ7NuASLGehEcMmVWslpYWxo4d6xDoI0mMHTu211tUaQbBRGBT2XxTse0tJH1a0v8DvgZcmWI9sGcPNDY6CMwqmEPgwPTl95f5weKIWBwR7wauAT7f0TKSLpfUIKmhubm57ytbvx5aWx0EZmZl0gyCzcCksvnaYltnlgHndPRCRCyJiPqIqB9/IJeF8IghM+uB++67D0kUSn3GEJdmEKwCpkqaLGk4MB9YUb6ApPL7RP4RsC7FevYFwbRpqa7GzAa3pUuX8sEPfpClS5emto69e/em9t69ldqooYholbQAeJBk+OgtEfGspBuAhohYASyQdDqwB9gGXJRWPUASBBMmwJgxqa7GzPrBn/85rF7dv+953HFw001dLvLaa6/xi1/8gkcffZSzzjqLL37xi+zdu5drrrmGBx54gGHDhnHZZZexcOFCVq1axVVXXcXrr7/OQQcdxMMPP8y9995LQ0MD3/nOdwD4yEc+wtVXX82sWbM4+OCD+eQnP8nPf/5zFi9ezCOPPMJPf/pTdu3axcknn8z3v/99JNHY2MgVV1xBc3MzVVVV/OM//iNf/OIX+ehHP8o55yQ7Ti644ALOO+885s6d29XH6ZFUzyOIiJXAynZt15U9vyrN9e/HI4bMrBs/+clPmDNnDkcffTRjx47liSee4PHHH2fjxo2sXr2a6upqXnnlFXbv3s3HPvYx7r77bk444QR27NjByG7ugf76669z0kkn8c1vfhOAGTNmcN11SZd44YUXcv/993PWWWdxwQUXsGjRIs4991xaWlpoa2vj0ksv5cYbb+Scc85h+/bt/PKXv+T222/vl8+cahBUlIgkCM4/P+tKzKwnuvnmnpalS5dy1VXJd9T58+ezdOlSNmzYwBVXXEF1ddJlvv3tb+eZZ55hwoQJnHDCCQCMHj262/euqqpi3rx5b84/+uijfO1rX2Pnzp288sorvPe972XWrFls3ryZc889F0hOEAM49dRT+dSnPkVzczP33nsv8+bNe7OeA5WfINi6Nbng3PTpWVdiZhXqlVde4ZFHHuGZZ55BEnv37kXSm519T1RXV9PW1vbmfPmY/hEjRlBVVfVm+6c+9SkaGhqYNGkS119/fbfj/z/+8Y/zox/9iGXLlnHrrbf28tN1LvPhowPGI4bMrBvLly/nwgsv5IUXXmDjxo1s2rSJyZMnM3PmTL7//e/T2toKJIExbdo0tmzZwqpVqwB49dVXaW1tpa6ujtWrV9PW1samTZt4/PHHO1xXqdMfN24cr732GsuXLwfgkEMOoba2lvvuuw+AN954g507dwJw8cUXc1NxS2nGjBn99rkdBGZmRUuXLn1zl0zJvHnz2LJlC0ceeSTHHnssM2fO5K677mL48OHcfffdLFy4kJkzZzJ79mxaWlo45ZRTmDx5MjNmzODKK6/k+OOP73Bdhx56KJdddhnHHHMMH/7wh9+y1fHDH/6Qm2++mWOPPZaTTz6ZF198EYDDDz+c6dOnc8kll/Tr51ZE+ld16E/19fXR0NDQ+x/8yU/g1lvhxz+GYfnJP7PBZM2aNUz37ttO7dy5k/e97308+eSTjOli9GNHv0dJT0REfUfL56dHnDsX7rvPIWBmg9LPf/5zpk+fzsKFC7sMgb7Iz8FiM7NB7PTTT+eFF15I5b399djMKspg211dafry+3MQmFnFGDFiBC+//LLDoI9K9yMonXvQU941ZGYVo7a2lqamJg7oKsM5V7pDWW84CMysYtTU1PTqzlrWP7xryMws5xwEZmY55yAwM8u5QXdmsaRmoK+DaccBL/VjOWkbTPUOplphcNU7mGqFwVXvYKoVDqzeoyKiw1s8DrogOBCSGjo7xboSDaZ6B1OtMLjqHUy1wuCqdzDVCunV611DZmY55yAwM8u5vAXBkqwL6KXBVO9gqhUGV72DqVYYXPUOplohpXpzdYzAzMz2l7ctAjMza8dBYGaWc7kJAklzJK2V1ChpUdb1dEbSJEmPSnpO0rOSrsq6pp6QVCXpKUn3Z11LVyQdKmm5pIKkNZJ+P+uauiLpM8W/g/+UtFRS7y4rmTJJt0jaKuk/y9reLukhSeuKj4dlWWNJJ7V+vfi38LSkf5J0aJY1lnRUa9lrn5UUksb11/pyEQSSqoDFwBnADOB8Sf135+f+1Qp8NiJmAL8HfLqCay13FbAm6yJ64NvAAxHxHmAmFVyzpInAlUB9RBwDVAHzs61qP7cBc9q1LQIejoipwMPF+UpwG/vX+hBwTEQcCzwPXDvQRXXiNvavFUmTgD8EftOfK8tFEAAnAo0RsT4idgPLgLkZ19ShiNgSEU8Wn79K0lFNzLaqrkmqBf4I+EHWtXRF0hjgD4B/AIiI3RHxu2yr6lY1MFJSNTAK+G3G9bxFRPwb8Eq75rnA7cXntwPnDGhRneio1oj4WUS0Fmd/BfTu+s0p6eT3CnAj8D+Bfh3lk5cgmAhsKptvosI7VwBJdcD7gf/ItpJu3UTyx9mWdSHdmAw0A7cWd2P9QNLbsi6qMxGxGfgGybe/LcD2iPhZtlX1yOERsaX4/EXg8CyL6YVPAP8n6yI6I2kusDkift3f752XIBh0JB0M3Av8eUTsyLqezkj6CLA1Ip7IupYeqAaOB74bEe8HXqdydlvsp7hvfS5JgL0TeJukP822qt6JZHx6xY9Rl/RXJLtl78y6lo5IGgX8JXBdGu+flyDYDEwqm68ttlUkSTUkIXBnRPw463q6cQpwtqSNJLvcPiTpR9mW1KkmoCkiSltYy0mCoVKdDmyIiOaI2AP8GDg545p64v9LmgBQfNyacT1dknQx8BHggqjcE6veTfKF4NfF/7Va4ElJR/THm+clCFYBUyVNljSc5IDbioxr6pAkkezDXhMR38q6nu5ExLURURsRdSS/10cioiK/tUbEi8AmSdOKTacBz2VYUnd+A/yepFHFv4vTqOCD22VWABcVn18E/CTDWrokaQ7Jbs2zI2Jn1vV0JiKeiYh3RERd8X+tCTi++Dd9wHIRBMWDQQuAB0n+ke6JiGezrapTpwAXknyzXl2czsy6qCFkIXCnpKeB44AvZ1xPp4pbLsuBJ4FnSP5fK+qSCJKWAo8B0yQ1SboU+AowW9I6kq2ar2RZY0kntX4HOAR4qPi/9r1MiyzqpNb01le5W0JmZjYQcrFFYGZmnXMQmJnlnIPAzCznHARmZjnnIDAzyzkHgVmRpL1lQ3ZX9+dVaiXVdXQlSbNKUJ11AWYVZFdEHJd1EWYDzVsEZt2QtFHS1yQ9I+lxSVOK7XWSHiley/5hSUcW2w8vXtv+18WpdFmIKkl/X7y/wM8kjSwuf2Xx/hNPS1qW0ce0HHMQmO0zst2uoY+VvbY9It5HcibqTcW2/wXcXryW/Z3AzcX2m4F/jYiZJNcyKp3FPhVYHBHvBX4HzCu2LwLeX3yfK9L6cGad8ZnFZkWSXouIgzto3wh8KCLWFy8I+GJEjJX0EjAhIvYU27dExDhJzUBtRLxR9h51wEPFm7Ug6RqgJiL+RtIDwGvAfcB9EfFayh/V7C28RWDWM9HJ8954o+z5XvYdo/sjkjvoHQ+sKt6ExmzAOAjMeuZjZakdhSUAAACqSURBVI+PFZ//kn23jrwA+Pfi84eBP4M37+U8prM3lTQMmBQRjwLXAGOA/bZKzNLkbx5m+4yUtLps/oGIKA0hPax4xdI3gPOLbQtJ7nb2OZI7n11SbL8KWFK8YuReklDYQseqgB8Vw0LAzYPg9pk2xPgYgVk3iscI6iPipaxrMUuDdw2ZmeWctwjMzHLOWwRmZjnnIDAzyzkHgZlZzjkIzMxyzkFgZpZz/wWGXSQM3DftYwAAAABJRU5ErkJggg==\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"KrBU2sNw9dT5","colab_type":"text"},"source":["####**How To Implement HW2 Dependency Parser**\n","\n","In HW2 we will implement the Graph-based Dependency Parser presented by Kiperwasser and Goldberg. In their [paper](https://https://arxiv.org/pdf/1603.04351.pdf), Kiperwasser and Goldberg proposed a Bidirectional LSTM model to extract features from the words and POS tags of a sentence, and generate an adjacency matrix representing the dependency edge scores between every two nodes (words) in the sentence. This matrix is then used by the Chu-Liu-Edmonds algorithm to create a valid parse tree.\\\n","For further details, please read sections 3 (Our Approach), 5 (Graph-based Parser),  Implementation details and Hyperparameter tuning under section 6 (Experiments and Results) from the [paper](https://arxiv.org/pdf/1603.04351.pdf).\\\n","**Please note:** instead of using the max-margin loss function presented in section 5 of the paper, we shall minimize the negative log-likelihood loss function ($NLLLoss$) which you will implement in your code:\n","$$\\min_{\\theta} NLLLoss(D;\\theta) = \\\\ \\min_{\\theta}\\sum_{(X^i,Y^i) \\in D} \\sum_{(h,m) \\in Y^i} -\\frac{1}{|Y^i|} \\cdot log(P(S^i_{h,m}|X^i,\\theta))$$\n","$$P(S^i_{h,m}|X^i,\\theta)=\\frac{exp(S^i_{h,m})}{\\sum_{j=1}^{|Y^i|} exp(S^i_{j,m})}=Softmax(S^i_{h,m})$$\n","Where:\n","\n","* $ D = \\{(X^i,Y^i)\\}_{i=1}^n $, Dataset consisting of $n$ (sentence, true tree) pairs. \n","* $X^i = \\{x_0=ROOT,x_1,...,x_{k_i}\\}$ is the full sequence of words in the sentence.\n","* $Y^i=\\{(h,m)\\}$ is the set of all (head_index, modifier_index) edges in the **true** dependency tree of sentence $X^i$. $|Y^i|=k_i$.\n","* $S^i \\in R^{(k_i+1)^2}$ is the score matrix for all possible (head, modifier) edges in the dependency graph of sentence $X^i$.\n","The cell $S^i_{h,m}$ refers to the score of $h$ being the head of $m$ in sentence $X^i$.\n","* $\\theta$ are the network's learned parameters\n","\n","Below we give a basic structure for the network's code implementation.\n"]},{"cell_type":"code","metadata":{"id":"oT3fXF0CEds8","colab_type":"code","outputId":"d0c27b75-2622-4ea0-8402-ab03dca8dc26","executionInfo":{"status":"error","timestamp":1589711500267,"user_tz":-180,"elapsed":1579681,"user":{"displayName":"Eyal Ben David","photoUrl":"","userId":"13627541310241359464"}},"colab":{"base_uri":"https://localhost:8080/","height":129}},"source":["from chu_liu_edmonds import decode_mst\n","\n","\n","class KiperwasserDependencyParser(nn.Module):\n","    def __init__(self, *args):\n","      super(KiperwasserDependencyParser, self).__init__()\n","      self.word_embedding = # Implement embedding layer for words (can be new or pretrained - word2vec/glove)\n","      self.pos_embedding = # Implement embedding layer for POS tags\n","      self.hidden_dim = self.word_embedding.embedding_dim + self.pos_embedding.embedding_dim\n","      self.encoder = # Implement BiLSTM module which is fed with word+pos embeddings and outputs hidden representations\n","      self.edge_scorer = # Implement a sub-module to calculate the scores for all possible edges in sentence dependency graph\n","      self.decoder = decode_mst # This is used to produce the maximum spannning tree during inference\n","      self.loss_function = # Implement the loss function described above\n","\n","    def forward(self, sentence):\n","      word_idx_tensor, pos_idx_tensor, true_tree_heads = sentence\n","\n","      # Pass word_idx and pos_idx through their embedding layers\n","\n","      # Concat both embedding outputs\n","\n","      # Get Bi-LSTM hidden representation for each word+pos in sentence\n","\n","      # Get score for each possible edge in the parsing graph, construct score matrix     \n","        \n","      # Use Chu-Liu-Edmonds to get the predicted parse tree T' given the calculated score matrix\n","\n","      # Calculate the negative log likelihood loss described above\n","      \n","      return loss, predicted_tree"],"execution_count":0,"outputs":[{"output_type":"error","ename":"SyntaxError","evalue":"ignored","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-15-d4d5aea84d5a>\"\u001b[0;36m, line \u001b[0;32m7\u001b[0m\n\u001b[0;31m    self.word_embedding = # Implement embedding layer for words (can be new or pretrained - word2vec/glove)\u001b[0m\n\u001b[0m                                                                                                           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"]}]},{"cell_type":"markdown","metadata":{"id":"sKd1f-irlKaH","colab_type":"text"},"source":["## <img src=\"https://img.icons8.com/dusk/64/000000/prize.png\" style=\"height:50px;display:inline\"> Credits\n","* Much of the code above is adjusted from  <a href=\"https://www.kaggle.com/krishanudb/lstm-character-word-pos-tag-model-pytorch/data\">this Kaggle tutorial</a>\n","* By <a href=\"https://github.com/eyalbd2\">Eyal Ben David</a> and <a href=\"https://github.com/nadavo\">Nadav Oved </a>"]}]}